{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Running an ensemble forecast\n",
    "\n",
    "This example shows how to run an ensemble of 10 forecasts using the `SpeedyEns` class. \n",
    "\n",
    "For this example, we will execute these steps:\n",
    "\n",
    "* Create an ensemble of models starting from a reference atmosphere. The same boundary conditions are used\n",
    "  for each member.\n",
    "* Perturb the initial temperature field with an uncorrelated gaussian noise with a  0.1$^\\circ$K standard deviation.\n",
    "  Note that this perturbations are neither physical or optimal with respect to the error growth! They are only used\n",
    "  to display how to use the `SpeedyEns` class.\n",
    "* Run the ensemble forecast for 3 months, with the first month considered as the \"spinup\" period. Hence, the results from the first month are discarded.\n",
    "* Compute the error growth over time for the temperature and the U winds.\n",
    "\n",
    "Let's get started. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Google colab fix\n",
    "\n",
    "***IMPORTANT***\n",
    "\n",
    "If you are running this notebook in Google Colab, uncomment and execute\n",
    "the following lines to install pySPEEDY and its dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !apt-get install libproj-dev proj-data proj-bin\n",
    "# !apt-get install libgeos-dev libnetcdf-dev libnetcdff-dev\n",
    "\n",
    "# !pip uninstall --yes shapely\n",
    "# !pip install shapely --no-binary shapely\n",
    "# !pip install cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Temporary fix for https://github.com/SciTools/cartopy/issues/1869 proposed by @rcomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/SciTools/cartopy/master/tools/cartopy_feature_download.py\n",
    "# !python cartopy_feature_download.py physical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we install pySPEEDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -v git+https://github.com/aperezhortal/pySPEEDY.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "End of Colab setup.\n",
    "\n",
    "### Running the ensemble forecast\n",
    "\n",
    "Let's run the ensemble forecast, keeping the output once a day (except during the spinup period).\n",
    "To store the forecast in memory, we will use the `ModelCheckpoint` callback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from pyspeedy import SpeedyEns\n",
    "from pyspeedy.callbacks import DiagnosticCheck, ModelCheckpoint\n",
    "\n",
    "# Definitions\n",
    "number_of_members = 10\n",
    "start_date = datetime(1980, 1, 1)  # Simulation start date (datetime object).\n",
    "end_date = datetime(1980, 2, 29)  # Simulation end date.\n",
    "spinup_date = datetime(1980, 2, 1)  # End of spinup period.\n",
    "\n",
    "# Create an instance of the speedy model.\n",
    "model_ens = SpeedyEns(\n",
    "    number_of_members,\n",
    "    start_date=start_date,  # Simulation start date (datetime object).\n",
    "    end_date=end_date,  # Simulation end date.\n",
    ")\n",
    "# At this point, each ensemble member contains an \"empty\" (not initialized) the model state.\n",
    "# Let's initialized them.\n",
    "# To do that, we will iterate over each member, set the boundary conditions, and add a random perturbation.\n",
    "for member in model_ens:\n",
    "    # Set the default boundary conditions derived from the ERA reanalysis.\n",
    "    member.set_bc()\n",
    "    # Add a perturbation to the temperature field in the grid space (not in the spectral one)\n",
    "    member[\"t_grid\"] += np.random.normal(0.0, 0.01, member[\"t_grid\"].shape)\n",
    "    # Since the prognostic variables used for the model integration are in the spectral space,\n",
    "    # convert all the grid variables to the spectral space (temperature is among these variables).\n",
    "    member.grid2spectral()\n",
    "\n",
    "# Et voilÃ , our ensemble is initialized.\n",
    "\n",
    "# Now, initialized the callback that will store the forecast in a dataframe with selected variables.\n",
    "# The dataframe with the data is stored in the \"dataframe\" attribute of the\n",
    "# created ModelCheckpoint instance.\n",
    "model_checkpoints = ModelCheckpoint(\n",
    "    interval=36,  # Every how many time steps we will save the output file. 36 -> once per day.\n",
    "    verbose=True,  # Prind progress messages\n",
    "    variables=None,  # Which variables to output. If none, save the most commonly used variables.\n",
    "    spinup_date=spinup_date,  # End of spinup period\n",
    ")\n",
    "\n",
    "# We will also add a callback that run a diagnostic check every 36 steps,\n",
    "# checking that some diagnostic values are within range.\n",
    "# If the check fails, an exception is raised and the model stops.\n",
    "diag_checks = DiagnosticCheck(interval=160)\n",
    "\n",
    "# Run the model passing our callback.\n",
    "# IMPORANT: This will the ensemble forecast in parallel, running a single member per thread.\n",
    "model_ens.run(callbacks=[model_checkpoints, diag_checks])\n",
    "# After the ensemble model is run, the model state contains the values from the last integration step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The time series of the selected variables are stored in a dataframe inside the `model_checkpoints` object that we pass as a callback to the model run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the stored dataframe in the model checkout callback.\n",
    "model_checkpoints.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Growth of the ensemble spread over time\n",
    "\n",
    "Let's compute the time series of the ensemble spread for temperature and the U wind.\n",
    "The spread is computed following  ([Fortin et al., 2014](https://journals.ametsoc.org/view/journals/hydr/15/4/jhm-d-14-0008_1.xml)):\n",
    "\n",
    "\\begin{equation}\n",
    "spr_{\\phi} = \\sqrt{ N^{-1} \\sum\\limits_{i}^N \n",
    "\\left[ (M-1)^{-1}\n",
    "\\sum\\limits_{m}^M \\left( \\phi_m(i) -\\overline{ \\phi(i) } \\right)^2\n",
    "\\right]}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\phi$ denotes a variable (e.g. U or Temperature).\n",
    "* $\\phi_m(i)$ its value at grid point ``i'' for the $m^{th}$ member .\n",
    "* the overbar indicates the ensemble average.\n",
    "* $\\sum\\limits_{m}^M$: sumation over the ensemble members.\n",
    "* $N^{-1} \\sum\\limits_{i}^N$: sumation over the grid points.\n",
    "\n",
    "That is, the spread is computed byby first computing the variance over the ensemble for each grid point, and the averaging the variances for all grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_dataset = model_checkpoints.dataframe\n",
    "\n",
    "spr_ds = ens_dataset.var(dim=\"ens\").mean(dim=[\"lev\", \"lat\", \"lon\"]).apply(np.sqrt)\n",
    "# Copy attributes from the ens_dataset\n",
    "for var in spr_ds:\n",
    "    spr_ds[var].attrs.update(**ens_dataset[var].attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "spr_ds[\"u\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), dpi=300)\n",
    "axs = axs.ravel()\n",
    "labels = [\"U wind\", \"Temperature\"]\n",
    "units = []\n",
    "for ax, var, label in zip(axs, [\"u\", \"t\"], labels):\n",
    "    spr_ds[var].plot(ax=ax)\n",
    "    ax.set_title(f\"Spread growth for {label}\")\n",
    "    units = spr_ds[var].attrs[\"units\"]\n",
    "    ax.set_ylabel(f\"$spr_{label[0]}$ [{units}]\")\n",
    "    ax.set_xticks(ax.get_xticks()[:-1])  # Remove the last tick that looks bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Now let's plot the spread map for the surface temperature field at the beginning and the end of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spr_ds = (\n",
    "    ens_dataset.std(dim=\"ens\").apply(np.sqrt).isel(lev=0)\n",
    ")  # keep first level (surface)\n",
    "# Copy attributes from the ens_dataset\n",
    "for var in spr_ds:\n",
    "    spr_ds[var].attrs.update(**ens_dataset[var].attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cartopy.feature import OCEAN\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2, 1, subplot_kw=dict(projection=ccrs.PlateCarree()), figsize=(10, 8)\n",
    ")\n",
    "\n",
    "lon = spr_ds[\"lon\"]\n",
    "\n",
    "for i, time_idx in enumerate([0, -1]):\n",
    "    ax = axs[i]\n",
    "    plt.sca(ax)\n",
    "    ax.set_title(\n",
    "        f\"Surface temperature spread [$^\\circ$C]\"\n",
    "    )  # Add title for each subplot.\n",
    "    ax.set_global()  # Set global extention\n",
    "    ax.coastlines()  # Add coastlines\n",
    "    ax.add_feature(OCEAN)  # Add oceans\n",
    "\n",
    "    data_to_plot = spr_ds[\"t\"].isel(time=time_idx)\n",
    "    lon = spr_ds[\"lon\"]\n",
    "    lat = spr_ds[\"lat\"]\n",
    "\n",
    "    # Copy the longitude=0 degrees data to longitude=360 to have continuous plots\n",
    "    data_to_plot, lon = add_cyclic_point(data_to_plot, coord=lon, axis=1)\n",
    "    cs = ax.pcolormesh(\n",
    "        lon.data,\n",
    "        lat.data,\n",
    "        data_to_plot.data,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        cmap=\"jet\",\n",
    "        shading=\"auto\",\n",
    "    )\n",
    "    cbar = plt.colorbar(cs, label=f\"Spread [$^\\circ$C]\")\n",
    "_ = plt.subplots_adjust(wspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
